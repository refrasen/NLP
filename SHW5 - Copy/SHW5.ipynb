{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHW5: WordNet\n",
    "In this homework you will be exploring WordNet by finding hyponyms of a synset throughout a text and building synset clusters.  \n",
    "\n",
    "This homework will be due **Tuesday, November 13 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll start off by importing a few modules. We'll also be defining a few functions to parse the Wordnet files for us to use. **Please do not import any additional libraries beyond the ones below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def read_index_file(filename):\n",
    "    \n",
    "    words_to_first_synsets={}\n",
    "    first_synsets_to_words={}\n",
    "    with open(filename) as file:\n",
    "        for i in range(29):\n",
    "            file.readline()\n",
    "            \n",
    "        for line in file:\n",
    "            cols = line.rstrip().split(\" \")\n",
    "            term = cols[0]\n",
    "            p_cnt = int(cols[3], 16);\n",
    "            first_synset_index = 6+p_cnt\n",
    "\n",
    "            # A word (like \"bank\") can belong to multiple synsets, so select just one;\n",
    "            # the first is typically the most frequently used for that word\n",
    "            first_synset = cols[first_synset_index]\n",
    "            words_to_first_synsets[term] = first_synset\n",
    "\n",
    "            if first_synset not in first_synsets_to_words:\n",
    "                first_synsets_to_words[first_synset] = set()\n",
    "\n",
    "            first_synsets_to_words[first_synset].add(term)\n",
    "            \n",
    "    return words_to_first_synsets, first_synsets_to_words\n",
    "\n",
    "\n",
    "def read_data_file(filename):\n",
    "\n",
    "    hyponyms = {}\n",
    "    with open(filename) as file:\n",
    "    \n",
    "        # skip header\n",
    "        for i in range(29):\n",
    "            file.readline()\n",
    "\n",
    "        for line in file:        \n",
    "            words = []\n",
    "            cols = line.rstrip().split(\" \")\n",
    "            synset_id = cols[0]\n",
    "            numWords = int(cols[3], 16);\n",
    "\n",
    "            numptr_index = 6+((numWords-1) * 2)\n",
    "            numPtrs = int(cols[numptr_index])\n",
    "\n",
    "            for i in range(0, numPtrs):\n",
    "                pointer_symbol = cols[numptr_index+(i * 4) + 1]\n",
    "                pointed_synset = cols[numptr_index+(i * 4) + 2]\n",
    "                \n",
    "                if pointer_symbol == '~': # hyponym relation\n",
    "                    if synset_id not in hyponyms:\n",
    "                        hyponyms[synset_id] = set()\n",
    "                    hyponyms[synset_id].add(pointed_synset)\n",
    "\n",
    "    return hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Hyponym Identification\n",
    "For this problem, we will be using the WordNet hyponym tree in order to identify all occurences of a hyponym of a given synset in a piece of text. To begin, we call the functions defined above to get the relevant information.  \n",
    "\n",
    "`word2first_synset` is a dictionary that maps a word to its first synset, and `first_synset2word` is a dictionary that maps a synset to all words that have that synset as their first synset. Note that for this homework, we are considering only the first (which is usually the most common) synset for each word.  \n",
    "`hyponyms` is a dictionary that maps a synset to a set of synsets which are direct hyponyms of the given synset. This gives the tree structure of hypernym/hyponym relationships.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping word to the first synset it is contained in, and synset to words in the synset\n",
    "word2first_synset, first_synset2word = read_index_file('index.noun')\n",
    "\n",
    "# Dictionary of synset to a set of synsets that are direct hyponyms of the synset\n",
    "hyponyms = read_data_file('data.noun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1\n",
    "Implement `get_hyponym_terms`, which gets all the terms included in the set of all hyponyms of the designated synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyponym_terms(synset_id, hyponyms, first_synsets_to_words):\n",
    "    \n",
    "    terms = set()\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we are able to identify whether a particular word or phrase is a hyponym of a given synset. Now we can move on to using this function to help identify the locations of hyponyms in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2\n",
    "Implement `get_synset_locations`, which takes in a specified text (represented as multiple lines of tokenized words) and returns locations of where any hyponyms of a given word, where each location is a nested tuple of the format `(line, (start_index, end_index))`. The start index is inclusive and the end index is exclusive.\n",
    "\n",
    "For example, if the word is 'mammal', and the 5th line of the text is \"Dogs , such as the poodle and german shepherd make wonderful pets .\" you should add `(4, (0, 1))`, `(4, (5, 6))`, and `(4, (7, 9))` to the locations list, as `dog`, `poodle`, and `german_shepherd` are hyponyms of 'mammal'.  \n",
    "\n",
    "Assume `text` is a list of lines, where each line is a word-tokenized (by spaces) string representation of a paragraph of text, and `word` is the word we want to find the hyponyms of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_locations(text, word, hyponyms, first_synset2word):\n",
    "    \n",
    "    locations = []\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    \n",
    "    return locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined below will help visualize where the hyponyms have been located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text_with_bolded_hyponyms(text, word, hyponyms, first_synset2word):\n",
    "    locations = get_synset_locations(text, word, hyponyms, first_synset2word)\n",
    "    \n",
    "    text_print = [t.split() for t in text]\n",
    "    for line_index, word_index in locations:\n",
    "        text_print[line_index][word_index[0]] = '**' + text_print[line_index][word_index[0]]\n",
    "        text_print[line_index][word_index[1]-1] = text_print[line_index][word_index[1]-1] + '**'\n",
    "    \n",
    "    for l in text_print:\n",
    "        display(Markdown((' '.join(l))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above functions implemented, we can now see how well we're able to identify hyponyms in text. Run the cell immediately below to read the text file, and then the following cell to display the text, wherein all hyponym of the given word (in this case, 'mammal'), will be bolded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('literary.texts.txt', 'r') as f:\n",
    "    lines = [l.rstrip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_text_with_bolded_hyponyms(lines, 'mammal', hyponyms, first_synset2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to change 'mammal' in the above cell to see different hyponyms being identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Synset Clustering\n",
    "In this next problem, we will be generating clusters from synsets in order to find which synset are most similar to some words that are not contained in Wordnet.  \n",
    "\n",
    "We begin by reading in our GloVe word embeddings, trained on a Twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = {}\n",
    "with open('glove.twitter.27B.25d.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        glove_dict[line.split()[0]] = np.array(line.split()[1:], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1\n",
    "Create clusters for each synset by finding the point that maximizes the cosine similarity of all the embeddings of the words in the synset. The resultant dictionary should contain a mapping between the synset ID and the optimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(first_synset2word, glove_dict):\n",
    "    \n",
    "    clusters = {}\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have a few words outside of Wordnet's vocabulary. We'll check the most similar synset from the synset clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_wordnet = ['minigame', 'grandmama', 'nocebo', 'crazycatlady', 'blogoversary', 'self-motivation',\n",
    "                  'bioshock', 'horcrux', 'pokemon', 'allnighter', 'belieber', 'facebook', 'ransomware',\n",
    "                  'bokeh', 'crowdfunding']\n",
    "\n",
    "synset_clusters = create_clusters(first_synset2word, glove_dict)\n",
    "\n",
    "for word in out_of_wordnet:\n",
    "    dists = []\n",
    "    for key, val in synset_clusters.items():\n",
    "        dists.append((key, np.dot(glove_dict[word], val) / np.linalg.norm(val)))\n",
    "    closest = sorted(dists, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    print('Closest synset to %s: %s' % (word, ', '.join(first_synset2word[closest])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.2\n",
    "Choose three of the above out of WordNet words and write a comment about each of them, answering the following questions: Was the most similar synset what you expected, or did it surprise you? Why do you think that synet was the most similar, based on what you know about WordNet, word embeddings, and the data that the embeddings were trained on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(write your response here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
